2025-12-15 06:38:22.803622: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:From /workspace/bottleneck-main/tf-gnn-samples/models/sparse_graph_model.py:307: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/dpu_utils/tfutils/gradratiologgingoptimizer.py:19: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /workspace/bottleneck-main/tf-gnn-samples/models/sparse_graph_model.py:71: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

2025-12-15 06:38:41.749163: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz
2025-12-15 06:38:41.753258: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2bcc2a60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2025-12-15 06:38:41.753363: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2025-12-15 06:38:41.755388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2025-12-15 06:38:42.018273: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2bd340b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-12-15 06:38:42.018690: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6
2025-12-15 06:38:42.020704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: 
name: NVIDIA RTX A5000 major: 8 minor: 6 memoryClockRate(GHz): 1.695
pciBusID: 0000:57:00.0
2025-12-15 06:38:42.021118: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2025-12-15 06:38:42.027485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2025-12-15 06:38:42.029376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2025-12-15 06:38:42.030000: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2025-12-15 06:38:42.031016: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2025-12-15 06:38:42.032706: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2025-12-15 06:38:42.033218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2025-12-15 06:38:42.037143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0
2025-12-15 06:38:42.037256: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2025-12-15 06:38:42.369403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Device interconnect StreamExecutor with strength 1 edge matrix:
2025-12-15 06:38:42.369674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212]      0 
2025-12-15 06:38:42.370070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 0:   N 
2025-12-15 06:38:42.373352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22011 MB memory) -> physical GPU (device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:57:00.0, compute capability: 8.6)
WARNING:tensorflow:From /workspace/bottleneck-main/tf-gnn-samples/models/sparse_graph_model.py:77: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /workspace/bottleneck-main/tf-gnn-samples/tasks/sparse_graph_task.py:140: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /workspace/bottleneck-main/tf-gnn-samples/models/sparse_graph_model.py:136: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bottleneck-main/tf-gnn-samples/models/sparse_graph_model.py:140: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

WARNING:tensorflow:From /workspace/bottleneck-main/tf-gnn-samples/gnns/rgat.py:75: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/dpu_utils/tfutils/unsortedsegmentops.py:26: The name tf.unsorted_segment_max is deprecated. Please use tf.math.unsorted_segment_max instead.

WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/dpu_utils/tfutils/unsortedsegmentops.py:34: The name tf.unsorted_segment_sum is deprecated. Please use tf.math.unsorted_segment_sum instead.

WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/dpu_utils/tfutils/unsortedsegmentops.py:35: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /workspace/bottleneck-main/tf-gnn-samples/utils/utils.py:116: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.

WARNING:tensorflow:From /workspace/bottleneck-main/tf-gnn-samples/tasks/qm9_task.py:221: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /workspace/bottleneck-main/tf-gnn-samples/models/sparse_graph_model.py:154: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.

WARNING:tensorflow:From /workspace/bottleneck-main/tf-gnn-samples/models/sparse_graph_model.py:155: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From /workspace/bottleneck-main/tf-gnn-samples/models/sparse_graph_model.py:159: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From /workspace/bottleneck-main/tf-gnn-samples/models/sparse_graph_model.py:264: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From /workspace/bottleneck-main/tf-gnn-samples/models/sparse_graph_model.py:284: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/indexed_slices.py:423: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
WARNING:tensorflow:From /workspace/bottleneck-main/tf-gnn-samples/models/sparse_graph_model.py:91: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /workspace/bottleneck-main/tf-gnn-samples/models/sparse_graph_model.py:92: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.

2025-12-15 06:38:53.004640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
Loading task/model-specific default parameters from tasks/default_hypers/QM9_RGAT.json.
 Loading QM9 data from data/qm9/train.jsonl.gz.
 Loading QM9 data from data/qm9/valid.jsonl.gz.
 Loading QM9 data from data/qm9/test.jsonl.gz.
Last layer: FA
Model has 617617 parameters.
Run QM9_RGAT_2025-12-15-06-38-41_77510 starting.
 Using the following task params: {"task_ids": [7], "add_self_loop_edges": true, "tie_fwd_bkwd_edges": true, "use_graph": true, "activation_function": "tanh", "out_layer_dropout_keep_prob": 1.0}
 Using the following model params: {"max_nodes_in_batch": 20000, "graph_num_layers": 8, "graph_num_timesteps_per_layer": 1, "graph_layer_input_dropout_keep_prob": 0.9, "graph_dense_between_every_num_gnn_layers": 32, "graph_model_activation_function": "tanh", "graph_residual_connection_every_num_layers": 2, "graph_inter_layer_norm": false, "max_epochs": 10000, "patience": 25, "min_epochs": 0, "optimizer": "RMSProp", "learning_rate": 0.0005800837190772856, "learning_rate_decay": 0.98, "lr_for_num_graphs_per_batch": null, "momentum": 0.85, "clamp_gradient_norm": 1.0, "random_seed": 5, "last_layer_fa": true, "hidden_size": 128, "num_heads": 8, "graph_activation_function": "elu"}
== Epoch 1
Running epoch 1 (training), batch 0 (has 1099 graphs). Loss so far: 0.4505Running epoch 1 (training), batch 1 (has 1103 graphs). Loss so far: 0.4711Running epoch 1 (training), batch 2 (has 1113 graphs). Loss so far: 0.4818Running epoch 1 (training), batch 3 (has 1116 graphs). Loss so far: 0.4909Running epoch 1 (training), batch 4 (has 1107 graphs). Loss so far: 0.4966Running epoch 1 (training), batch 5 (has 1107 graphs). Loss so far: 0.4944Running epoch 1 (training), batch 6 (has 1108 graphs). Loss so far: 0.4940Running epoch 1 (training), batch 7 (has 1117 graphs). Loss so far: 0.4901Running epoch 1 (training), batch 8 (has 1111 graphs). Loss so far: 0.4889Running epoch 1 (training), batch 9 (has 1109 graphs). Loss so far: 0.4930Running epoch 1 (training), batch 10 (has 1117 graphs). Loss so far: 0.4929Running epoch 1 (training), batch 11 (has 1109 graphs). Loss so far: 0.4978Running epoch 1 (training), batch 12 (has 1108 graphs). Loss so far: 0.4955Running epoch 1 (training), batch 13 (has 1112 graphs). Loss so far: 0.4968Running epoch 1 (training), batch 14 (has 1114 graphs). Loss so far: 0.4939Running epoch 1 (training), batch 15 (has 1117 graphs). Loss so far: 0.4951Running epoch 1 (training), batch 16 (has 1102 graphs). Loss so far: 0.4943Running epoch 1 (training), batch 17 (has 1114 graphs). Loss so far: 0.4964Running epoch 1 (training), batch 18 (has 1106 graphs). Loss so far: 0.4953Running epoch 1 (training), batch 19 (has 1112 graphs). Loss so far: 0.4962Running epoch 1 (training), batch 20 (has 1107 graphs). Loss so far: 0.4951Running epoch 1 (training), batch 21 (has 1110 graphs). Loss so far: 0.4941Running epoch 1 (training), batch 22 (has 1104 graphs). Loss so far: 0.4931Running epoch 1 (training), batch 23 (has 1107 graphs). Loss so far: 0.4929Running epoch 1 (training), batch 24 (has 1111 graphs). Loss so far: 0.4919Running epoch 1 (training), batch 25 (has 1107 graphs). Loss so far: 0.4929Running epoch 1 (training), batch 26 (has 1105 graphs). Loss so far: 0.4921Running epoch 1 (training), batch 27 (has 1108 graphs). Loss so far: 0.4912Running epoch 1 (training), batch 28 (has 1123 graphs). Loss so far: 0.4906Running epoch 1 (training), batch 29 (has 1108 graphs). Loss so far: 0.4912Running epoch 1 (training), batch 30 (has 1099 graphs). Loss so far: 0.4889Running epoch 1 (training), batch 31 (has 1114 graphs). Loss so far: 0.4881Running epoch 1 (training), batch 32 (has 1115 graphs). Loss so far: 0.4881Running epoch 1 (training), batch 33 (has 1105 graphs). Loss so far: 0.4871Running epoch 1 (training), batch 34 (has 1110 graphs). Loss so far: 0.4872Running epoch 1 (training), batch 35 (has 1104 graphs). Loss so far: 0.4867Running epoch 1 (training), batch 36 (has 1100 graphs). Loss so far: 0.4866Running epoch 1 (training), batch 37 (has 1102 graphs). Loss so far: 0.4866Running epoch 1 (training), batch 38 (has 1096 graphs). Loss so far: 0.4857Running epoch 1 (training), batch 39 (has 1117 graphs). Loss so far: 0.4859Running epoch 1 (training), batch 40 (has 1102 graphs). Loss so far: 0.4858Running epoch 1 (training), batch 41 (has 1110 graphs). Loss so far: 0.4859Running epoch 1 (training), batch 42 (has 1109 graphs). Loss so far: 0.4856Running epoch 1 (training), batch 43 (has 1107 graphs). Loss so far: 0.4843Running epoch 1 (training), batch 44 (has 1105 graphs). Loss so far: 0.4843Running epoch 1 (training), batch 45 (has 1109 graphs). Loss so far: 0.4842Running epoch 1 (training), batch 46 (has 1106 graphs). Loss so far: 0.4848Running epoch 1 (training), batch 47 (has 1103 graphs). Loss so far: 0.4844Running epoch 1 (training), batch 48 (has 1114 graphs). Loss so far: 0.4839Running epoch 1 (training), batch 49 (has 1109 graphs). Loss so far: 0.4832Running epoch 1 (training), batch 50 (has 1099 graphs). Loss so far: 0.4828Running epoch 1 (training), batch 51 (has 1107 graphs). Loss so far: 0.4832Running epoch 1 (training), batch 52 (has 1117 graphs). Loss so far: 0.4830Running epoch 1 (training), batch 53 (has 1114 graphs). Loss so far: 0.4827Running epoch 1 (training), batch 54 (has 1110 graphs). Loss so far: 0.4832Running epoch 1 (training), batch 55 (has 1102 graphs). Loss so far: 0.4829Running epoch 1 (training), batch 56 (has 1111 graphs). Loss so far: 0.4831Running epoch 1 (training), batch 57 (has 1121 graphs). Loss so far: 0.4835Running epoch 1 (training), batch 58 (has 1110 graphs). Loss so far: 0.4837Running epoch 1 (training), batch 59 (has 1107 graphs). Loss so far: 0.4834Running epoch 1 (training), batch 60 (has 1108 graphs). Loss so far: 0.4829Running epoch 1 (training), batch 61 (has 1113 graphs). Loss so far: 0.4830Running epoch 1 (training), batch 62 (has 1107 graphs). Loss so far: 0.4826Running epoch 1 (training), batch 63 (has 1105 graphs). Loss so far: 0.4830Running epoch 1 (training), batch 64 (has 1116 graphs). Loss so far: 0.4831Running epoch 1 (training), batch 65 (has 1108 graphs). Loss so far: 0.4826Running epoch 1 (training), batch 66 (has 1106 graphs). Loss so far: 0.4823Running epoch 1 (training), batch 67 (has 1117 graphs). Loss so far: 0.4821Running epoch 1 (training), batch 68 (has 1106 graphs). Loss so far: 0.4822Running epoch 1 (training), batch 69 (has 1109 graphs). Loss so far: 0.4829Running epoch 1 (training), batch 70 (has 1103 graphs). Loss so far: 0.4831Running epoch 1 (training), batch 71 (has 1109 graphs). Loss so far: 0.4832Running epoch 1 (training), batch 72 (has 1095 graphs). Loss so far: 0.4830Running epoch 1 (training), batch 73 (has 1115 graphs). Loss so far: 0.4827Running epoch 1 (training), batch 74 (has 1116 graphs). Loss so far: 0.4827Running epoch 1 (training), batch 75 (has 1109 graphs). Loss so far: 0.4829Running epoch 1 (training), batch 76 (has 1105 graphs). Loss so far: 0.4832Running epoch 1 (training), batch 77 (has 1124 graphs). Loss so far: 0.4833Running epoch 1 (training), batch 78 (has 1109 graphs). Loss so far: 0.4837Running epoch 1 (training), batch 79 (has 1098 graphs). Loss so far: 0.4832Running epoch 1 (training), batch 80 (has 1111 graphs). Loss so far: 0.4830Running epoch 1 (training), batch 81 (has 1112 graphs). Loss so far: 0.4834Running epoch 1 (training), batch 82 (has 1099 graphs). Loss so far: 0.4836Running epoch 1 (training), batch 83 (has 1107 graphs). Loss so far: 0.4833Running epoch 1 (training), batch 84 (has 1102 graphs). Loss so far: 0.4833Running epoch 1 (training), batch 85 (has 1113 graphs). Loss so far: 0.4829Running epoch 1 (training), batch 86 (has 1115 graphs). Loss so far: 0.4829Running epoch 1 (training), batch 87 (has 1100 graphs). Loss so far: 0.4831Running epoch 1 (training), batch 88 (has 1107 graphs). Loss so far: 0.4833Running epoch 1 (training), batch 89 (has 1104 graphs). Loss so far: 0.4830Running epoch 1 (training), batch 90 (has 1109 graphs). Loss so far: 0.4826Running epoch 1 (training), batch 91 (has 1116 graphs). Loss so far: 0.4831Running epoch 1 (training), batch 92 (has 1108 graphs). Loss so far: 0.4827Running epoch 1 (training), batch 93 (has 1112 graphs). Loss so far: 0.4825Running epoch 1 (training), batch 94 (has 1113 graphs). Loss so far: 0.4824Running epoch 1 (training), batch 95 (has 1107 graphs). Loss so far: 0.4824Running epoch 1 (training), batch 96 (has 1108 graphs). Loss so far: 0.4825Running epoch 1 (training), batch 97 (has 1107 graphs). Loss so far: 0.4825Running epoch 1 (training), batch 98 (has 1105 graphs). Loss so far: 0.4826Running epoch 1 (training), batch 99 (has 704 graphs). Loss so far: 0.4827[K Train: loss: 0.48269 || MAEs: 7:0.77141 | Error Ratios: 7:185.19093 || graphs/sec: 5317.39 | nodes/sec: 95871 | edges/sec: 294227
Running epoch 1 (validation), batch 0 (has 1103 graphs). Loss so far: 0.4571Running epoch 1 (validation), batch 1 (has 1100 graphs). Loss so far: 0.4611Running epoch 1 (validation), batch 2 (has 1105 graphs). Loss so far: 0.4682Running epoch 1 (validation), batch 3 (has 1104 graphs). Loss so far: 0.4709Running epoch 1 (validation), batch 4 (has 1102 graphs). Loss so far: 0.4627Running epoch 1 (validation), batch 5 (has 1108 graphs). Loss so far: 0.4686Running epoch 1 (validation), batch 6 (has 1119 graphs). Loss so far: 0.4728Running epoch 1 (validation), batch 7 (has 1109 graphs). Loss so far: 0.4717Running epoch 1 (validation), batch 8 (has 1114 graphs). Loss so far: 0.4757Running epoch 1 (validation), batch 9 (has 36 graphs). Loss so far: 0.4764[K Valid: loss: 0.47638 || MAEs: 7:0.76712 | Error Ratios: 7:184.16108 || graphs/sec: 6949.99 | nodes/sec: 125489 | edges/sec: 385048
  (Best epoch so far, target metric decreased to 0.47638 from inf. Saving to 'trained_models/QM9_RGAT_2025-12-15-06-38-41_77510_best_model.pickle')
== Epoch 2
Running epoch 2 (training), batch 0 (has 1109 graphs). Loss so far: 0.4820Running epoch 2 (training), batch 1 (has 1112 graphs). Loss so far: 0.4628Running epoch 2 (training), batch 2 (has 1111 graphs). Loss so far: 0.4698Running epoch 2 (training), batch 3 (has 1110 graphs). Loss so far: 0.4699Running epoch 2 (training), batch 4 (has 1110 graphs). Loss so far: 0.4800Running epoch 2 (training), batch 5 (has 1110 graphs). Loss so far: 0.4909Running epoch 2 (training), batch 6 (has 1118 graphs). Loss so far: 0.4907Running epoch 2 (training), batch 7 (has 1115 graphs). Loss so far: 0.4886Running epoch 2 (training), batch 8 (has 1114 graphs). Loss so far: 0.4836Running epoch 2 (training), batch 9 (has 1112 graphs). Loss so far: 0.4871Running epoch 2 (training), batch 10 (has 1107 graphs). Loss so far: 0.4833Running epoch 2 (training), batch 11 (has 1102 graphs). Loss so far: 0.4804Running epoch 2 (training), batch 12 (has 1116 graphs). Loss so far: 0.4815Running epoch 2 (training), batch 13 (has 1117 graphs). Loss so far: 0.4832Running epoch 2 (training), batch 14 (has 1099 graphs). Loss so far: 0.4840Running epoch 2 (training), batch 15 (has 1106 graphs). Loss so far: 0.4862Running epoch 2 (training), batch 16 (has 1106 graphs). Loss so far: 0.4846Running epoch 2 (training), batch 17 (has 1106 graphs). Loss so far: 0.4842Running epoch 2 (training), batch 18 (has 1104 graphs). Loss so far: 0.4836Running epoch 2 (training), batch 19 (has 1108 graphs). Loss so far: 0.4840Running epoch 2 (training), batch 20 (has 1113 graphs). Loss so far: 0.4849Running epoch 2 (training), batch 21 (has 1105 graphs). Loss so far: 0.4839Running epoch 2 (training), batch 22 (has 1107 graphs). Loss so far: 0.4842Running epoch 2 (training), batch 23 (has 1103 graphs). Loss so far: 0.4832Running epoch 2 (training), batch 24 (has 1117 graphs). Loss so far: 0.4857Running epoch 2 (training), batch 25 (has 1102 graphs). Loss so far: 0.4852Running epoch 2 (training), batch 26 (has 1110 graphs). Loss so far: 0.4837Running epoch 2 (training), batch 27 (has 1107 graphs). Loss so far: 0.4839Running epoch 2 (training), batch 28 (has 1109 graphs). Loss so far: 0.4844Running epoch 2 (training), batch 29 (has 1114 graphs). Loss so far: 0.4854Running epoch 2 (training), batch 30 (has 1118 graphs). Loss so far: 0.4845Running epoch 2 (training), batch 31 (has 1113 graphs). Loss so far: 0.4855Running epoch 2 (training), batch 32 (has 1110 graphs). Loss so far: 0.4844Running epoch 2 (training), batch 33 (has 1108 graphs). Loss so far: 0.4831Running epoch 2 (training), batch 34 (has 1103 graphs). Loss so far: 0.4827Running epoch 2 (training), batch 35 (has 1105 graphs). Loss so far: 0.4829Running epoch 2 (training), batch 36 (has 1101 graphs). Loss so far: 0.4830Running epoch 2 (training), batch 37 (has 1107 graphs). Loss so far: 0.4824Running epoch 2 (training), batch 38 (has 1106 graphs). Loss so far: 0.4824Running epoch 2 (training), batch 39 (has 1111 graphs). Loss so far: 0.4817Running epoch 2 (training), batch 40 (has 1116 graphs). Loss so far: 0.4824Running epoch 2 (training), batch 41 (has 1114 graphs). Loss so far: 0.4825Running epoch 2 (training), batch 42 (has 1110 graphs). Loss so far: 0.4827Running epoch 2 (training), batch 43 (has 1109 graphs). Loss so far: 0.4818Running epoch 2 (training), batch 44 (has 1108 graphs). Loss so far: 0.4824Running epoch 2 (training), batch 45 (has 1112 graphs). Loss so far: 0.4815Running epoch 2 (training), batch 46 (has 1104 graphs). Loss so far: 0.4807Running epoch 2 (training), batch 47 (has 1114 graphs). Loss so far: 0.4802Running epoch 2 (training), batch 48 (has 1111 graphs). Loss so far: 0.4804Running epoch 2 (training), batch 49 (has 1109 graphs). Loss so far: 0.4802Running epoch 2 (training), batch 50 (has 1114 graphs). Loss so far: 0.4800Running epoch 2 (training), batch 51 (has 1113 graphs). Loss so far: 0.4798Running epoch 2 (training), batch 52 (has 1116 graphs). Loss so far: 0.4797Running epoch 2 (training), batch 53 (has 1110 graphs). Loss so far: 0.4797Running epoch 2 (training), batch 54 (has 1109 graphs). Loss so far: 0.4798Running epoch 2 (training), batch 55 (has 1107 graphs). Loss so far: 0.4792Running epoch 2 (training), batch 56 (has 1110 graphs). Loss so far: 0.4791Running epoch 2 (training), batch 57 (has 1099 graphs). Loss so far: 0.4790Running epoch 2 (training), batch 58 (has 1109 graphs). Loss so far: 0.4788Running epoch 2 (training), batch 59 (has 1104 graphs). Loss so far: 0.4788Running epoch 2 (training), batch 60 (has 1102 graphs). Loss so far: 0.4781Running epoch 2 (training), batch 61 (has 1103 graphs). Loss so far: 0.4783Running epoch 2 (training), batch 62 (has 1107 graphs). Loss so far: 0.4786Running epoch 2 (training), batch 63 (has 1110 graphs). Loss so far: 0.4782Running epoch 2 (training), batch 64 (has 1104 graphs). Loss so far: 0.4781Running epoch 2 (training), batch 65 (has 1106 graphs). Loss so far: 0.4784Running epoch 2 (training), batch 66 (has 1105 graphs). Loss so far: 0.4782Running epoch 2 (training), batch 67 (has 1116 graphs). Loss so far: 0.4788Running epoch 2 (training), batch 68 (has 1107 graphs). Loss so far: 0.4781Running epoch 2 (training), batch 69 (has 1108 graphs). Loss so far: 0.4785Running epoch 2 (training), batch 70 (has 1104 graphs). Loss so far: 0.4781Running epoch 2 (training), batch 71 (has 1103 graphs). Loss so far: 0.4776Running epoch 2 (training), batch 72 (has 1119 graphs). Loss so far: 0.4778Running epoch 2 (training), batch 73 (has 1110 graphs). Loss so far: 0.4779Running epoch 2 (training), batch 74 (has 1109 graphs). Loss so far: 0.4781Running epoch 2 (training), batch 75 (has 1112 graphs). Loss so far: 0.4782Running epoch 2 (training), batch 76 (has 1104 graphs). Loss so far: 0.4780Running epoch 2 (training), batch 77 (has 1107 graphs). Loss so far: 0.4776Running epoch 2 (training), batch 78 (has 1102 graphs). Loss so far: 0.4775Running epoch 2 (training), batch 79 (has 1099 graphs). Loss so far: 0.4776Running epoch 2 (training), batch 80 (has 1111 graphs). Loss so far: 0.4773Running epoch 2 (training), batch 81 (has 1104 graphs). Loss so far: 0.4769Running epoch 2 (training), batch 82 (has 1114 graphs). Loss so far: 0.4771Running epoch 2 (training), batch 83 (has 1112 graphs). Loss so far: 0.4774Running epoch 2 (training), batch 84 (has 1103 graphs). Loss so far: 0.4770Running epoch 2 (training), batch 85 (has 1105 graphs). Loss so far: 0.4772Running epoch 2 (training), batch 86 (has 1106 graphs). Loss so far: 0.4774Running epoch 2 (training), batch 87 (has 1114 graphs). Loss so far: 0.4773Running epoch 2 (training), batch 88 (has 1110 graphs). Loss so far: 0.4777Running epoch 2 (training), batch 89 (has 1116 graphs). Loss so far: 0.4774Running epoch 2 (training), batch 90 (has 1100 graphs). Loss so far: 0.4776Running epoch 2 (training), batch 91 (has 1114 graphs). Loss so far: 0.4778Running epoch 2 (training), batch 92 (has 1112 graphs). Loss so far: 0.4777Running epoch 2 (training), batch 93 (has 1112 graphs). Loss so far: 0.4776Running epoch 2 (training), batch 94 (has 1113 graphs). Loss so far: 0.4775Running epoch 2 (training), batch 95 (has 1103 graphs). Loss so far: 0.4774Running epoch 2 (training), batch 96 (has 1105 graphs). Loss so far: 0.4773Running epoch 2 (training), batch 97 (has 1108 graphs). Loss so far: 0.4766Running epoch 2 (training), batch 98 (has 1109 graphs). Loss so far: 0.4766Running epoch 2 (training), batch 99 (has 695 graphs). Loss so far: 0.4770[K Train: loss: 0.47695 || MAEs: 7:0.76631 | Error Ratios: 7:183.96524 || graphs/sec: 6569.69 | nodes/sec: 118449 | edges/sec: 363521
Running epoch 2 (validation), batch 0 (has 1103 graphs). Loss so far: 0.4497Running epoch 2 (validation), batch 1 (has 1100 graphs). Loss so far: 0.4534Running epoch 2 (validation), batch 2 (has 1105 graphs). Loss so far: 0.4605Running epoch 2 (validation), batch 3 (has 1104 graphs). Loss so far: 0.4632Running epoch 2 (validation), batch 4 (has 1102 graphs). Loss so far: 0.4551Running epoch 2 (validation), batch 5 (has 1108 graphs). Loss so far: 0.4610Running epoch 2 (validation), batch 6 (has 1119 graphs). Loss so far: 0.4655Running epoch 2 (validation), batch 7 (has 1109 graphs). Loss so far: 0.4643Running epoch 2 (validation), batch 8 (has 1114 graphs). Loss so far: 0.4684Running epoch 2 (validation), batch 9 (has 36 graphs). Loss so far: 0.4691[K Valid: loss: 0.46906 || MAEs: 7:0.76070 | Error Ratios: 7:182.61903 || graphs/sec: 14114.72 | nodes/sec: 254855 | edges/sec: 781992
  (Best epoch so far, target metric decreased to 0.46906 from 0.47638. Saving to 'trained_models/QM9_RGAT_2025-12-15-06-38-41_77510_best_model.pickle')
== Epoch 3
Running epoch 3 (training), batch 0 (has 1113 graphs). Loss so far: 0.4768Running epoch 3 (training), batch 1 (has 1115 graphs). Loss so far: 0.4733Running epoch 3 (training), batch 2 (has 1114 graphs). Loss so far: 0.4745Running epoch 3 (training), batch 3 (has 1113 graphs). Loss so far: 0.4710Running epoch 3 (training), batch 4 (has 1112 graphs). Loss so far: 0.4736Running epoch 3 (training), batch 5 (has 1117 graphs). Loss so far: 0.4817Running epoch 3 (training), batch 6 (has 1113 graphs). Loss so far: 0.4786Running epoch 3 (training), batch 7 (has 1112 graphs). Loss so far: 0.4736Running epoch 3 (training), batch 8 (has 1105 graphs). Loss so far: 0.4729Running epoch 3 (training), batch 9 (has 1112 graphs). Loss so far: 0.4743Running epoch 3 (training), batch 10 (has 1112 graphs). Loss so far: 0.4756Running epoch 3 (training), batch 11 (has 1109 graphs). Loss so far: 0.4730Running epoch 3 (training), batch 12 (has 1103 graphs). Loss so far: 0.4756Running epoch 3 (training), batch 13 (has 1114 graphs). Loss so far: 0.4757Running epoch 3 (training), batch 14 (has 1100 graphs). Loss so far: 0.4738Running epoch 3 (training), batch 15 (has 1104 graphs). Loss so far: 0.4751Running epoch 3 (training), batch 16 (has 1101 graphs). Loss so far: 0.4754Running epoch 3 (training), batch 17 (has 1105 graphs). Loss so far: 0.4745Running epoch 3 (training), batch 18 (has 1112 graphs). Loss so far: 0.4735Running epoch 3 (training), batch 19 (has 1104 graphs). Loss so far: 0.4720Running epoch 3 (training), batch 20 (has 1105 graphs). Loss so far: 0.4710Running epoch 3 (training), batch 21 (has 1115 graphs). Loss so far: 0.4719Running epoch 3 (training), batch 22 (has 1110 graphs). Loss so far: 0.4707Running epoch 3 (training), batch 23 (has 1106 graphs). Loss so far: 0.4711Running epoch 3 (training), batch 24 (has 1120 graphs). Loss so far: 0.4732Running epoch 3 (training), batch 25 (has 1111 graphs). Loss so far: 0.4737Running epoch 3 (training), batch 26 (has 1111 graphs). Loss so far: 0.4740Running epoch 3 (training), batch 27 (has 1112 graphs). Loss so far: 0.4743Running epoch 3 (training), batch 28 (has 1108 graphs). Loss so far: 0.4753Running epoch 3 (training), batch 29 (has 1119 graphs). Loss so far: 0.4760Running epoch 3 (training), batch 30 (has 1103 graphs). Loss so far: 0.4759Running epoch 3 (training), batch 31 (has 1115 graphs). Loss so far: 0.4763Running epoch 3 (training), batch 32 (has 1110 graphs). Loss so far: 0.4765Running epoch 3 (training), batch 33 (has 1110 graphs). Loss so far: 0.4774Running epoch 3 (training), batch 34 (has 1108 graphs). Loss so far: 0.4766Running epoch 3 (training), batch 35 (has 1105 graphs). Loss so far: 0.4775Running epoch 3 (training), batch 36 (has 1111 graphs). Loss so far: 0.4768Running epoch 3 (training), batch 37 (has 1107 graphs). Loss so far: 0.4767Running epoch 3 (training), batch 38 (has 1113 graphs). Loss so far: 0.4765Running epoch 3 (training), batch 39 (has 1108 graphs). Loss so far: 0.4767Running epoch 3 (training), batch 40 (has 1109 graphs). Loss so far: 0.4764Running epoch 3 (training), batch 41 (has 1103 graphs). Loss so far: 0.4766Running epoch 3 (training), batch 42 (has 1112 graphs). Loss so far: 0.4764Running epoch 3 (training), batch 43 (has 1107 graphs). Loss so far: 0.4766Running epoch 3 (training), batch 44 (has 1115 graphs). Loss so far: 0.4773Running epoch 3 (training), batch 45 (has 1107 graphs). Loss so far: 0.4776Running epoch 3 (training), batch 46 (has 1102 graphs). Loss so far: 0.4770Running epoch 3 (training), batch 47 (has 1106 graphs). Loss so far: 0.4774Running epoch 3 (training), batch 48 (has 1104 graphs). Loss so far: 0.4771Running epoch 3 (training), batch 49 (has 1112 graphs). Loss so far: 0.4776Running epoch 3 (training), batch 50 (has 1111 graphs). Loss so far: 0.4767Running epoch 3 (training), batch 51 (has 1108 graphs). Loss so far: 0.4772Running epoch 3 (training), batch 52 (has 1109 graphs). Loss so far: 0.4767Running epoch 3 (training), batch 53 (has 1117 graphs). Loss so far: 0.4773Running epoch 3 (training), batch 54 (has 1110 graphs). Loss so far: 0.4768Running epoch 3 (training), batch 55 (has 1106 graphs). Loss so far: 0.4770Running epoch 3 (training), batch 56 (has 1111 graphs). Loss so far: 0.4768Running epoch 3 (training), batch 57 (has 1109 graphs). Loss so far: 0.4762Running epoch 3 (training), batch 58 (has 1113 graphs). Loss so far: 0.4759Running epoch 3 (training), batch 59 (has 1105 graphs). Loss so far: 0.4753Running epoch 3 (training), batch 60 (has 1100 graphs). Loss so far: 0.4748Running epoch 3 (training), batch 61 (has 1112 graphs). Loss so far: 0.4742Running epoch 3 (training), batch 62 (has 1104 graphs). Loss so far: 0.4742Running epoch 3 (training), batch 63 (has 1098 graphs). Loss so far: 0.4737Running epoch 3 (training), batch 64 (has 1103 graphs). Loss so far: 0.4736Running epoch 3 (training), batch 65 (has 1113 graphs). Loss so far: 0.4733Running epoch 3 (training), batch 66 (has 1101 graphs). Loss so far: 0.4731Running epoch 3 (training), batch 67 (has 1110 graphs). Loss so far: 0.4728Running epoch 3 (training), batch 68 (has 1105 graphs). Loss so far: 0.4727Running epoch 3 (training), batch 69 (has 1107 graphs). Loss so far: 0.4726Running epoch 3 (training), batch 70 (has 1100 graphs). Loss so far: 0.4721Running epoch 3 (training), batch 71 (has 1113 graphs). Loss so far: 0.4727Running epoch 3 (training), batch 72 (has 1105 graphs). Loss so far: 0.4726Running epoch 3 (training), batch 73 (has 1108 graphs). Loss so far: 0.4726Running epoch 3 (training), batch 74 (has 1106 graphs). Loss so far: 0.4720Running epoch 3 (training), batch 75 (has 1109 graphs). Loss so far: 0.4714Running epoch 3 (training), batch 76 (has 1099 graphs). Loss so far: 0.4709Running epoch 3 (training), batch 77 (has 1118 graphs). Loss so far: 0.4711Running epoch 3 (training), batch 78 (has 1114 graphs). Loss so far: 0.4710Running epoch 3 (training), batch 79 (has 1112 graphs). Loss so far: 0.4710Running epoch 3 (training), batch 80 (has 1110 graphs). Loss so far: 0.4709Running epoch 3 (training), batch 81 (has 1102 graphs). Loss so far: 0.4709Running epoch 3 (training), batch 82 (has 1101 graphs). Loss so far: 0.4703Running epoch 3 (training), batch 83 (has 1107 graphs). Loss so far: 0.4701Running epoch 3 (training), batch 84 (has 1112 graphs). Loss so far: 0.4702Running epoch 3 (training), batch 85 (has 1106 graphs). Loss so far: 0.4701Running epoch 3 (training), batch 86 (has 1107 graphs). Loss so far: 0.4698Running epoch 3 (training), batch 87 (has 1104 graphs). Loss so far: 0.4696Running epoch 3 (training), batch 88 (has 1111 graphs). Loss so far: 0.4695Running epoch 3 (training), batch 89 (has 1113 graphs). Loss so far: 0.4692Running epoch 3 (training), batch 90 (has 1108 graphs). Loss so far: 0.4688Running epoch 3 (training), batch 91 (has 1104 graphs). Loss so far: 0.4687Running epoch 3 (training), batch 92 (has 1109 graphs). Loss so far: 0.4683Running epoch 3 (training), batch 93 (has 1108 graphs). Loss so far: 0.4683Running epoch 3 (training), batch 94 (has 1117 graphs). Loss so far: 0.4683Running epoch 3 (training), batch 95 (has 1111 graphs). Loss so far: 0.4681Running epoch 3 (training), batch 96 (has 1113 graphs). Loss so far: 0.4681Running epoch 3 (training), batch 97 (has 1105 graphs). Loss so far: 0.4678Running epoch 3 (training), batch 98 (has 1114 graphs). Loss so far: 0.4675Running epoch 3 (training), batch 99 (has 690 graphs). Loss so far: 0.4675[K Train: loss: 0.46746 || MAEs: 7:0.75786 | Error Ratios: 7:181.93667 || graphs/sec: 7444.70 | nodes/sec: 134225 | edges/sec: 411938
Running epoch 3 (validation), batch 0 (has 1103 graphs). Loss so far: 0.4381Running epoch 3 (validation), batch 1 (has 1100 graphs). Loss so far: 0.4417Running epoch 3 (validation), batch 2 (has 1105 graphs). Loss so far: 0.4488Running epoch 3 (validation), batch 3 (has 1104 graphs). Loss so far: 0.4512Running epoch 3 (validation), batch 4 (has 1102 graphs). Loss so far: 0.4434Running epoch 3 (validation), batch 5 (has 1108 graphs). Loss so far: 0.4491Running epoch 3 (validation), batch 6 (has 1119 graphs). Loss so far: 0.4538Running epoch 3 (validation), batch 7 (has 1109 graphs). Loss so far: 0.4527Running epoch 3 (validation), batch 8 (has 1114 graphs). Loss so far: 0.4568Running epoch 3 (validation), batch 9 (has 36 graphs). Loss so far: 0.4574[K Valid: loss: 0.45739 || MAEs: 7:0.75030 | Error Ratios: 7:180.12185 || graphs/sec: 15880.62 | nodes/sec: 286740 | edges/sec: 879827
  (Best epoch so far, target metric decreased to 0.45739 from 0.46906. Saving to 'trained_models/QM9_RGAT_2025-12-15-06-38-41_77510_best_model.pickle')
== Epoch 4
Running epoch 4 (training), batch 0 (has 1107 graphs). Loss so far: 0.4527Running epoch 4 (training), batch 1 (has 1112 graphs). Loss so far: 0.4707Running epoch 4 (training), batch 2 (has 1113 graphs). Loss so far: 0.4681Running epoch 4 (training), batch 3 (has 1104 graphs). Loss so far: 0.4609Running epoch 4 (training), batch 4 (has 1109 graphs). Loss so far: 0.4616Running epoch 4 (training), batch 5 (has 1113 graphs). Loss so far: 0.4646Running epoch 4 (training), batch 6 (has 1106 graphs). Loss so far: 0.4631Running epoch 4 (training), batch 7 (has 1118 graphs). Loss so far: 0.4596Running epoch 4 (training), batch 8 (has 1098 graphs). Loss so far: 0.4590Running epoch 4 (training), batch 9 (has 1121 graphs). Loss so far: 0.4600Running epoch 4 (training), batch 10 (has 1099 graphs). Loss so far: 0.4598Running epoch 4 (training), batch 11 (has 1117 graphs). Loss so far: 0.4575Running epoch 4 (training), batch 12 (has 1112 graphs). Loss so far: 0.4591Running epoch 4 (training), batch 13 (has 1108 graphs). Loss so far: 0.4597Running epoch 4 (training), batch 14 (has 1099 graphs). Loss so far: 0.4588Running epoch 4 (training), batch 15 (has 1108 graphs). Loss so far: 0.4577Running epoch 4 (training), batch 16 (has 1114 graphs). Loss so far: 0.4589Running epoch 4 (training), batch 17 (has 1111 graphs). Loss so far: 0.4576Running epoch 4 (training), batch 18 (has 1102 graphs). Loss so far: 0.4563Running epoch 4 (training), batch 19 (has 1108 graphs). Loss so far: 0.4561Running epoch 4 (training), batch 20 (has 1111 graphs). Loss so far: 0.4565Running epoch 4 (training), batch 21 (has 1107 graphs). Loss so far: 0.4563Running epoch 4 (training), batch 22 (has 1115 graphs). Loss so far: 0.4555Running epoch 4 (training), batch 23 (has 1097 graphs). Loss so far: 0.4534Running epoch 4 (training), batch 24 (has 1113 graphs). Loss so far: 0.4541Running epoch 4 (training), batch 25 (has 1111 graphs). Loss so far: 0.4549Running epoch 4 (training), batch 26 (has 1112 graphs). Loss so far: 0.4546Running epoch 4 (training), batch 27 (has 1115 graphs). Loss so far: 0.4550Running epoch 4 (training), batch 28 (has 1102 graphs). Loss so far: 0.4554Running epoch 4 (training), batch 29 (has 1114 graphs). Loss so far: 0.4557Running epoch 4 (training), batch 30 (has 1104 graphs). Loss so far: 0.4565Running epoch 4 (training), batch 31 (has 1107 graphs). Loss so far: 0.4568Running epoch 4 (training), batch 32 (has 1109 graphs). Loss so far: 0.4555Running epoch 4 (training), batch 33 (has 1108 graphs). Loss so far: 0.4552Running epoch 4 (training), batch 34 (has 1114 graphs). Loss so far: 0.4555Running epoch 4 (training), batch 35 (has 1111 graphs). Loss so far: 0.4558Running epoch 4 (training), batch 36 (has 1102 graphs). Loss so far: 0.4562Running epoch 4 (training), batch 37 (has 1112 graphs). Loss so far: 0.4562Running epoch 4 (training), batch 38 (has 1121 graphs). Loss so far: 0.4569Running epoch 4 (training), batch 39 (has 1105 graphs). Loss so far: 0.4573Running epoch 4 (training), batch 40 (has 1098 graphs). Loss so far: 0.4573Running epoch 4 (training), batch 41 (has 1106 graphs). Loss so far: 0.4563Running epoch 4 (training), batch 42 (has 1113 graphs). Loss so far: 0.4563Running epoch 4 (training), batch 43 (has 1103 graphs). Loss so far: 0.4555Running epoch 4 (training), batch 44 (has 1094 graphs). Loss so far: 0.4550Running epoch 4 (training), batch 45 (has 1112 graphs). Loss so far: 0.4547Running epoch 4 (training), batch 46 (has 1111 graphs). Loss so far: 0.4549Running epoch 4 (training), batch 47 (has 1109 graphs). Loss so far: 0.4554Running epoch 4 (training), batch 48 (has 1114 graphs). Loss so far: 0.4552Running epoch 4 (training), batch 49 (has 1112 graphs). Loss so far: 0.4549Running epoch 4 (training), batch 50 (has 1105 graphs). Loss so far: 0.4554Running epoch 4 (training), batch 51 (has 1109 graphs). Loss so far: 0.4551Running epoch 4 (training), batch 52 (has 1108 graphs). Loss so far: 0.4555Running epoch 4 (training), batch 53 (has 1108 graphs). Loss so far: 0.4557Running epoch 4 (training), batch 54 (has 1115 graphs). Loss so far: 0.4559Running epoch 4 (training), batch 55 (has 1110 graphs). Loss so far: 0.4560Running epoch 4 (training), batch 56 (has 1109 graphs). Loss so far: 0.4558Running epoch 4 (training), batch 57 (has 1108 graphs). Loss so far: 0.4558Running epoch 4 (training), batch 58 (has 1094 graphs). Loss so far: 0.4553Running epoch 4 (training), batch 59 (has 1108 graphs). Loss so far: 0.4552Running epoch 4 (training), batch 60 (has 1112 graphs). Loss so far: 0.4553Running epoch 4 (training), batch 61 (has 1106 graphs). Loss so far: 0.4552Running epoch 4 (training), batch 62 (has 1116 graphs). Loss so far: 0.4549Running epoch 4 (training), batch 63 (has 1115 graphs). Loss so far: 0.4548Running epoch 4 (training), batch 64 (has 1096 graphs). Loss so far: 0.4542Running epoch 4 (training), batch 65 (has 1112 graphs). Loss so far: 0.4542Running epoch 4 (training), batch 66 (has 1105 graphs). Loss so far: 0.4542Running epoch 4 (training), batch 67 (has 1106 graphs). Loss so far: 0.4542Running epoch 4 (training), batch 68 (has 1108 graphs). Loss so far: 0.4544Running epoch 4 (training), batch 69 (has 1114 graphs). Loss so far: 0.4539Running epoch 4 (training), batch 70 (has 1108 graphs). Loss so far: 0.4538Running epoch 4 (training), batch 71 (has 1110 graphs). Loss so far: 0.4540Running epoch 4 (training), batch 72 (has 1114 graphs). Loss so far: 0.4541Running epoch 4 (training), batch 73 (has 1098 graphs). Loss so far: 0.4533Running epoch 4 (training), batch 74 (has 1119 graphs). Loss so far: 0.4534Running epoch 4 (training), batch 75 (has 1106 graphs). Loss so far: 0.4535Running epoch 4 (training), batch 76 (has 1102 graphs). Loss so far: 0.4529Running epoch 4 (training), batch 77 (has 1102 graphs). Loss so far: 0.4526Running epoch 4 (training), batch 78 (has 1116 graphs). Loss so far: 0.4527Running epoch 4 (training), batch 79 (has 1107 graphs). Loss so far: 0.4531Running epoch 4 (training), batch 80 (has 1110 graphs). Loss so far: 0.4531Running epoch 4 (training), batch 81 (has 1113 graphs). Loss so far: 0.4529Running epoch 4 (training), batch 82 (has 1099 graphs). Loss so far: 0.4523Running epoch 4 (training), batch 83 (has 1106 graphs). Loss so far: 0.4520Running epoch 4 (training), batch 84 (has 1126 graphs). Loss so far: 0.4522Running epoch 4 (training), batch 85 (has 1119 graphs). Loss so far: 0.4522Running epoch 4 (training), batch 86 (has 1115 graphs). Loss so far: 0.4522Running epoch 4 (training), batch 87 (has 1102 graphs). Loss so far: 0.4518Running epoch 4 (training), batch 88 (has 1105 graphs). Loss so far: 0.4511Running epoch 4 (training), batch 89 (has 1118 graphs). Loss so far: 0.4509Running epoch 4 (training), batch 90 (has 1103 graphs). Loss so far: 0.4508Running epoch 4 (training), batch 91 (has 1112 graphs). Loss so far: 0.4508Running epoch 4 (training), batch 92 (has 1103 graphs). Loss so far: 0.4504Running epoch 4 (training), batch 93 (has 1101 graphs). Loss so far: 0.4498Running epoch 4 (training), batch 94 (has 1107 graphs). Loss so far: 0.4498Running epoch 4 (training), batch 95 (has 1112 graphs). Loss so far: 0.4495Running epoch 4 (training), batch 96 (has 1106 graphs). Loss so far: 0.4491Running epoch 4 (training), batch 97 (has 1114 graphs). Loss so far: 0.4490Running epoch 4 (training), batch 98 (has 1100 graphs). Loss so far: 0.4483Running epoch 4 (training), batch 99 (has 704 graphs). Loss so far: 0.4483[K Train: loss: 0.44826 || MAEs: 7:0.74045 | Error Ratios: 7:177.75712 || graphs/sec: 6812.79 | nodes/sec: 122832 | edges/sec: 376972
Running epoch 4 (validation), batch 0 (has 1103 graphs). Loss so far: 0.3920Running epoch 4 (validation), batch 1 (has 1100 graphs). Loss so far: 0.3955Running epoch 4 (validation), batch 2 (has 1105 graphs). Loss so far: 0.4021Running epoch 4 (validation), batch 3 (has 1104 graphs). Loss so far: 0.4040Running epoch 4 (validation), batch 4 (has 1102 graphs). Loss so far: 0.3967Running epoch 4 (validation), batch 5 (has 1108 graphs). Loss so far: 0.4018Running epoch 4 (validation), batch 6 (has 1119 graphs). Loss so far: 0.4066Running epoch 4 (validation), batch 7 (has 1109 graphs). Loss so far: 0.4054Running epoch 4 (validation), batch 8 (has 1114 graphs). Loss so far: 0.4093Running epoch 4 (validation), batch 9 (has 36 graphs). Loss so far: 0.4098[K Valid: loss: 0.40978 || MAEs: 7:0.70702 | Error Ratios: 7:169.73339 || graphs/sec: 15469.77 | nodes/sec: 279322 | edges/sec: 857065
  (Best epoch so far, target metric decreased to 0.40978 from 0.45739. Saving to 'trained_models/QM9_RGAT_2025-12-15-06-38-41_77510_best_model.pickle')
== Epoch 5
Running epoch 5 (training), batch 0 (has 1102 graphs). Loss so far: 0.4070Running epoch 5 (training), batch 1 (has 1110 graphs). Loss so far: 0.3895Running epoch 5 (training), batch 2 (has 1111 graphs). Loss so far: 0.4048Running epoch 5 (training), batch 3 (has 1115 graphs). Loss so far: 0.3922Running epoch 5 (training), batch 4 (has 1115 graphs). Loss so far: 0.3979Running epoch 5 (training), batch 5 (has 1100 graphs). Loss so far: 0.3981Running epoch 5 (training), batch 6 (has 1105 graphs). Loss so far: 0.3950Running epoch 5 (training), batch 7 (has 1104 graphs). Loss so far: 0.3913Running epoch 5 (training), batch 8 (has 1116 graphs). Loss so far: 0.3944Running epoch 5 (training), batch 9 (has 1109 graphs). Loss so far: 0.3936Running epoch 5 (training), batch 10 (has 1104 graphs). Loss so far: 0.3923Running epoch 5 (training), batch 11 (has 1111 graphs). Loss so far: 0.3920Running epoch 5 (training), batch 12 (has 1109 graphs). Loss so far: 0.3927Running epoch 5 (training), batch 13 (has 1112 graphs). Loss so far: 0.3900Running epoch 5 (training), batch 14 (has 1114 graphs). Loss so far: 0.3904Running epoch 5 (training), batch 15 (has 1106 graphs). Loss so far: 0.3876Running epoch 5 (training), batch 16 (has 1106 graphs). Loss so far: 0.3862Running epoch 5 (training), batch 17 (has 1110 graphs). Loss so far: 0.3855Running epoch 5 (training), batch 18 (has 1097 graphs). Loss so far: 0.3838Running epoch 5 (training), batch 19 (has 1101 graphs). Loss so far: 0.3809Running epoch 5 (training), batch 20 (has 1111 graphs). Loss so far: 0.3792Running epoch 5 (training), batch 21 (has 1103 graphs). Loss so far: 0.3766Running epoch 5 (training), batch 22 (has 1104 graphs). Loss so far: 0.3729Running epoch 5 (training), batch 23 (has 1107 graphs). Loss so far: 0.3694Running epoch 5 (training), batch 24 (has 1101 graphs). Loss so far: 0.3658Running epoch 5 (training), batch 25 (has 1118 graphs). Loss so far: 0.3634Running epoch 5 (training), batch 26 (has 1098 graphs). Loss so far: 0.3601Running epoch 5 (training), batch 27 (has 1108 graphs). Loss so far: 0.3562Running epoch 5 (training), batch 28 (has 1108 graphs). Loss so far: 0.3522Running epoch 5 (training), batch 29 (has 1107 graphs). Loss so far: 0.3475Running epoch 5 (training), batch 30 (has 1110 graphs). Loss so far: 0.3437Running epoch 5 (training), batch 31 (has 1106 graphs). Loss so far: 0.3399Running epoch 5 (training), batch 32 (has 1116 graphs). Loss so far: 0.3350Running epoch 5 (training), batch 33 (has 1119 graphs). Loss so far: 0.3308Running epoch 5 (training), batch 34 (has 1116 graphs). Loss so far: 0.3265Running epoch 5 (training), batch 35 (has 1113 graphs). Loss so far: 0.3219Running epoch 5 (training), batch 36 (has 1110 graphs). Loss so far: 0.3169Running epoch 5 (training), batch 37 (has 1112 graphs). Loss so far: 0.3118Running epoch 5 (training), batch 38 (has 1107 graphs). Loss so far: 0.3067Running epoch 5 (training), batch 39 (has 1102 graphs). Loss so far: 0.3015Running epoch 5 (training), batch 40 (has 1106 graphs). Loss so far: 0.2970Running epoch 5 (training), batch 41 (has 1110 graphs). Loss so far: 0.2921Running epoch 5 (training), batch 42 (has 1116 graphs). Loss so far: 0.2874Running epoch 5 (training), batch 43 (has 1106 graphs). Loss so far: 0.2828Running epoch 5 (training), batch 44 (has 1101 graphs). Loss so far: 0.2784Running epoch 5 (training), batch 45 (has 1113 graphs). Loss so far: 0.2741Running epoch 5 (training), batch 46 (has 1108 graphs). Loss so far: 0.2701Running epoch 5 (training), batch 47 (has 1108 graphs). Loss so far: 0.2668Running epoch 5 (training), batch 48 (has 1105 graphs). Loss so far: 0.2633Running epoch 5 (training), batch 49 (has 1109 graphs). Loss so far: 0.2599Running epoch 5 (training), batch 50 (has 1107 graphs). Loss so far: 0.2560Running epoch 5 (training), batch 51 (has 1116 graphs). Loss so far: 0.2524Running epoch 5 (training), batch 52 (has 1105 graphs). Loss so far: 0.2493Running epoch 5 (training), batch 53 (has 1116 graphs). Loss so far: 0.2464Running epoch 5 (training), batch 54 (has 1109 graphs). Loss so far: 0.2433Running epoch 5 (training), batch 55 (has 1103 graphs). Loss so far: 0.2401Running epoch 5 (training), batch 56 (has 1116 graphs). Loss so far: 0.2372Running epoch 5 (training), batch 57 (has 1112 graphs). Loss so far: 0.2342Running epoch 5 (training), batch 58 (has 1099 graphs). Loss so far: 0.2314Running epoch 5 (training), batch 59 (has 1113 graphs). Loss so far: 0.2286Running epoch 5 (training), batch 60 (has 1105 graphs). Loss so far: 0.2258Running epoch 5 (training), batch 61 (has 1109 graphs). Loss so far: 0.2229Running epoch 5 (training), batch 62 (has 1101 graphs). Loss so far: 0.2202Running epoch 5 (training), batch 63 (has 1112 graphs). Loss so far: 0.2176Running epoch 5 (training), batch 64 (has 1104 graphs). Loss so far: 0.2150Running epoch 5 (training), batch 65 (has 1108 graphs). Loss so far: 0.2126Running epoch 5 (training), batch 66 (has 1123 graphs). Loss so far: 0.2102Running epoch 5 (training), batch 67 (has 1102 graphs). Loss so far: 0.2079Running epoch 5 (training), batch 68 (has 1114 graphs). Loss so far: 0.2056Running epoch 5 (training), batch 69 (has 1109 graphs). Loss so far: 0.2033Running epoch 5 (training), batch 70 (has 1112 graphs). Loss so far: 0.2011Running epoch 5 (training), batch 71 (has 1108 graphs). Loss so far: 0.1990Running epoch 5 (training), batch 72 (has 1110 graphs). Loss so far: 0.1972Running epoch 5 (training), batch 73 (has 1104 graphs). Loss so far: 0.1955Running epoch 5 (training), batch 74 (has 1112 graphs). Loss so far: 0.1936Running epoch 5 (training), batch 75 (has 1108 graphs). Loss so far: 0.1916Running epoch 5 (training), batch 76 (has 1111 graphs). Loss so far: 0.1898Running epoch 5 (training), batch 77 (has 1111 graphs). Loss so far: 0.1881Running epoch 5 (training), batch 78 (has 1109 graphs). Loss so far: 0.1864Running epoch 5 (training), batch 79 (has 1111 graphs). Loss so far: 0.1847Running epoch 5 (training), batch 80 (has 1105 graphs). Loss so far: 0.1829Running epoch 5 (training), batch 81 (has 1107 graphs). Loss so far: 0.1812Running epoch 5 (training), batch 82 (has 1102 graphs). Loss so far: 0.1796Running epoch 5 (training), batch 83 (has 1112 graphs). Loss so far: 0.1780Running epoch 5 (training), batch 84 (has 1103 graphs). Loss so far: 0.1765Running epoch 5 (training), batch 85 (has 1117 graphs). Loss so far: 0.1750Running epoch 5 (training), batch 86 (has 1109 graphs). Loss so far: 0.1733Running epoch 5 (training), batch 87 (has 1110 graphs). Loss so far: 0.1719Running epoch 5 (training), batch 88 (has 1108 graphs). Loss so far: 0.1704Running epoch 5 (training), batch 89 (has 1113 graphs). Loss so far: 0.1691Running epoch 5 (training), batch 90 (has 1113 graphs). Loss so far: 0.1677Running epoch 5 (training), batch 91 (has 1110 graphs). Loss so far: 0.1662Running epoch 5 (training), batch 92 (has 1107 graphs). Loss so far: 0.1649Running epoch 5 (training), batch 93 (has 1097 graphs). Loss so far: 0.1636Running epoch 5 (training), batch 94 (has 1110 graphs). Loss so far: 0.1625Running epoch 5 (training), batch 95 (has 1116 graphs). Loss so far: 0.1614Running epoch 5 (training), batch 96 (has 1113 graphs). Loss so far: 0.1603Running epoch 5 (training), batch 97 (has 1106 graphs). Loss so far: 0.1590Running epoch 5 (training), batch 98 (has 1110 graphs). Loss so far: 0.1577Running epoch 5 (training), batch 99 (has 700 graphs). Loss so far: 0.1569[K Train: loss: 0.15694 || MAEs: 7:0.39195 | Error Ratios: 7:94.09355 || graphs/sec: 7297.23 | nodes/sec: 131566 | edges/sec: 403778
Running epoch 5 (validation), batch 0 (has 1103 graphs). Loss so far: 0.0400Running epoch 5 (validation), batch 1 (has 1100 graphs). Loss so far: 0.0396Running epoch 5 (validation), batch 2 (has 1105 graphs). Loss so far: 0.0414Running epoch 5 (validation), batch 3 (has 1104 graphs). Loss so far: 0.0411Running epoch 5 (validation), batch 4 (has 1102 graphs). Loss so far: 0.0409Running epoch 5 (validation), batch 5 (has 1108 graphs). Loss so far: 0.0411Running epoch 5 (validation), batch 6 (has 1119 graphs). Loss so far: 0.0411Running epoch 5 (validation), batch 7 (has 1109 graphs). Loss so far: 0.0411Running epoch 5 (validation), batch 8 (has 1114 graphs). Loss so far: 0.0410Running epoch 5 (validation), batch 9 (has 36 graphs). Loss so far: 0.0410[K Valid: loss: 0.04103 || MAEs: 7:0.24662 | Error Ratios: 7:59.20451 || graphs/sec: 16246.76 | nodes/sec: 293351 | edges/sec: 900113
  (Best epoch so far, target metric decreased to 0.04103 from 0.40978. Saving to 'trained_models/QM9_RGAT_2025-12-15-06-38-41_77510_best_model.pickle')
== Epoch 6
Running epoch 6 (training), batch 0 (has 1107 graphs). Loss so far: 0.0448Running epoch 6 (training), batch 1 (has 1109 graphs). Loss so far: 0.0424Running epoch 6 (training), batch 2 (has 1112 graphs). Loss so far: 0.0417Running epoch 6 (training), batch 3 (has 1114 graphs). Loss so far: 0.0391Running epoch 6 (training), batch 4 (has 1106 graphs). Loss so far: 0.0380Running epoch 6 (training), batch 5 (has 1112 graphs). Loss so far: 0.0377Running epoch 6 (training), batch 6 (has 1110 graphs). Loss so far: 0.0379Running epoch 6 (training), batch 7 (has 1108 graphs). Loss so far: 0.0380Running epoch 6 (training), batch 8 (has 1102 graphs). Loss so far: 0.0379Running epoch 6 (training), batch 9 (has 1123 graphs). Loss so far: 0.0379Running epoch 6 (training), batch 10 (has 1115 graphs). Loss so far: 0.0377Running epoch 6 (training), batch 11 (has 1101 graphs). Loss so far: 0.0376Running epoch 6 (training), batch 12 (has 1111 graphs). Loss so far: 0.0379Running epoch 6 (training), batch 13 (has 1118 graphs). Loss so far: 0.0385Running epoch 6 (training), batch 14 (has 1109 graphs). Loss so far: 0.0394Running epoch 6 (training), batch 15 (has 1104 graphs). Loss so far: 0.0401Running epoch 6 (training), batch 16 (has 1108 graphs). Loss so far: 0.0408Running epoch 6 (training), batch 17 (has 1115 graphs). Loss so far: 0.0412Running epoch 6 (training), batch 18 (has 1110 graphs). Loss so far: 0.0410Running epoch 6 (training), batch 19 (has 1105 graphs). Loss so far: 0.0405Running epoch 6 (training), batch 20 (has 1108 graphs). Loss so far: 0.0400Running epoch 6 (training), batch 21 (has 1115 graphs). Loss so far: 0.0396Running epoch 6 (training), batch 22 (has 1102 graphs). Loss so far: 0.0394Running epoch 6 (training), batch 23 (has 1105 graphs). Loss so far: 0.0400Running epoch 6 (training), batch 24 (has 1110 graphs). Loss so far: 0.0411Running epoch 6 (training), batch 25 (has 1102 graphs). Loss so far: 0.0425Running epoch 6 (training), batch 26 (has 1107 graphs). Loss so far: 0.0433Running epoch 6 (training), batch 27 (has 1106 graphs). Loss so far: 0.0433Running epoch 6 (training), batch 28 (has 1112 graphs). Loss so far: 0.0427Running epoch 6 (training), batch 29 (has 1106 graphs). Loss so far: 0.0424Running epoch 6 (training), batch 30 (has 1104 graphs). Loss so far: 0.0424Running epoch 6 (training), batch 31 (has 1109 graphs). Loss so far: 0.0426Running epoch 6 (training), batch 32 (has 1118 graphs). Loss so far: 0.0425Running epoch 6 (training), batch 33 (has 1105 graphs). Loss so far: 0.0421Running epoch 6 (training), batch 34 (has 1117 graphs). Loss so far: 0.0418Running epoch 6 (training), batch 35 (has 1110 graphs). Loss so far: 0.0414Running epoch 6 (training), batch 36 (has 1108 graphs). Loss so far: 0.0411Running epoch 6 (training), batch 37 (has 1112 graphs). Loss so far: 0.0409Running epoch 6 (training), batch 38 (has 1109 graphs). Loss so far: 0.0409Running epoch 6 (training), batch 39 (has 1102 graphs). Loss so far: 0.0408Running epoch 6 (training), batch 40 (has 1107 graphs). Loss so far: 0.0409Running epoch 6 (training), batch 41 (has 1110 graphs). Loss so far: 0.0410Running epoch 6 (training), batch 42 (has 1107 graphs). Loss so far: 0.0415Running epoch 6 (training), batch 43 (has 1110 graphs). Loss so far: 0.0419Running epoch 6 (training), batch 44 (has 1108 graphs). Loss so far: 0.0424Running epoch 6 (training), batch 45 (has 1106 graphs). Loss so far: 0.0426Running epoch 6 (training), batch 46 (has 1120 graphs). Loss so far: 0.0425Running epoch 6 (training), batch 47 (has 1116 graphs). Loss so far: 0.0421Running epoch 6 (training), batch 48 (has 1111 graphs). Loss so far: 0.0419Running epoch 6 (training), batch 49 (has 1110 graphs). Loss so far: 0.0416Running epoch 6 (training), batch 50 (has 1102 graphs). Loss so far: 0.0413Running epoch 6 (training), batch 51 (has 1114 graphs). Loss so far: 0.0411Running epoch 6 (training), batch 52 (has 1112 graphs). Loss so far: 0.0408Running epoch 6 (training), batch 53 (has 1109 graphs). Loss so far: 0.0406Running epoch 6 (training), batch 54 (has 1105 graphs). Loss so far: 0.0405Running epoch 6 (training), batch 55 (has 1103 graphs). Loss so far: 0.0405Running epoch 6 (training), batch 56 (has 1116 graphs). Loss so far: 0.0404Running epoch 6 (training), batch 57 (has 1106 graphs). Loss so far: 0.0406Running epoch 6 (training), batch 58 (has 1117 graphs). Loss so far: 0.0409Running epoch 6 (training), batch 59 (has 1107 graphs). Loss so far: 0.0416Running epoch 6 (training), batch 60 (has 1098 graphs). Loss so far: 0.0420Running epoch 6 (training), batch 61 (has 1108 graphs). Loss so far: 0.0424Running epoch 6 (training), batch 62 (has 1113 graphs). Loss so far: 0.0423Running epoch 6 (training), batch 63 (has 1105 graphs). Loss so far: 0.0420Running epoch 6 (training), batch 64 (has 1107 graphs). Loss so far: 0.0419Running epoch 6 (training), batch 65 (has 1116 graphs). Loss so far: 0.0419Running epoch 6 (training), batch 66 (has 1114 graphs). Loss so far: 0.0420Running epoch 6 (training), batch 67 (has 1115 graphs). Loss so far: 0.0419Running epoch 6 (training), batch 68 (has 1103 graphs). Loss so far: 0.0416Running epoch 6 (training), batch 69 (has 1107 graphs). Loss so far: 0.0414Running epoch 6 (training), batch 70 (has 1117 graphs). Loss so far: 0.0413Running epoch 6 (training), batch 71 (has 1108 graphs). Loss so far: 0.0412Running epoch 6 (training), batch 72 (has 1108 graphs). Loss so far: 0.0410Running epoch 6 (training), batch 73 (has 1101 graphs). Loss so far: 0.0408Running epoch 6 (training), batch 74 (has 1102 graphs). Loss so far: 0.0406Running epoch 6 (training), batch 75 (has 1104 graphs). Loss so far: 0.0405Running epoch 6 (training), batch 76 (has 1101 graphs). Loss so far: 0.0403Running epoch 6 (training), batch 77 (has 1115 graphs). Loss so far: 0.0402Running epoch 6 (training), batch 78 (has 1105 graphs). Loss so far: 0.0401Running epoch 6 (training), batch 79 (has 1110 graphs). Loss so far: 0.0399Running epoch 6 (training), batch 80 (has 1105 graphs). Loss so far: 0.0398Running epoch 6 (training), batch 81 (has 1112 graphs). Loss so far: 0.0396Running epoch 6 (training), batch 82 (has 1107 graphs). Loss so far: 0.0394Running epoch 6 (training), batch 83 (has 1103 graphs). Loss so far: 0.0392Running epoch 6 (training), batch 84 (has 1103 graphs). Loss so far: 0.0390Running epoch 6 (training), batch 85 (has 1108 graphs). Loss so far: 0.0390Running epoch 6 (training), batch 86 (has 1110 graphs). Loss so far: 0.0390Running epoch 6 (training), batch 87 (has 1112 graphs). Loss so far: 0.0397Running epoch 6 (training), batch 88 (has 1105 graphs). Loss so far: 0.0410Running epoch 6 (training), batch 89 (has 1111 graphs). Loss so far: 0.0424Running epoch 6 (training), batch 90 (has 1111 graphs). Loss so far: 0.0423Running epoch 6 (training), batch 91 (has 1111 graphs). Loss so far: 0.0424Running epoch 6 (training), batch 92 (has 1105 graphs). Loss so far: 0.0433Running epoch 6 (training), batch 93 (has 1106 graphs). Loss so far: 0.0434Running epoch 6 (training), batch 94 (has 1103 graphs). Loss so far: 0.0433Running epoch 6 (training), batch 95 (has 1107 graphs). Loss so far: 0.0434Running epoch 6 (training), batch 96 (has 1118 graphs). Loss so far: 0.0435Running epoch 6 (training), batch 97 (has 1105 graphs). Loss so far: 0.0433Running epoch 6 (training), batch 98 (has 1107 graphs). Loss so far: 0.0432Running epoch 6 (training), batch 99 (has 694 graphs). Loss so far: 0.0432[K Train: loss: 0.04322 || MAEs: 7:0.22665 | Error Ratios: 7:54.41057 || graphs/sec: 7187.56 | nodes/sec: 129589 | edges/sec: 397709
Running epoch 6 (validation), batch 0 (has 1103 graphs). Loss so far: 0.0211Running epoch 6 (validation), batch 1 (has 1100 graphs). Loss so far: 0.0218Running epoch 6 (validation), batch 2 (has 1105 graphs). Loss so far: 0.0232Running epoch 6 (validation), batch 3 (has 1104 graphs). Loss so far: 0.0228Running epoch 6 (validation), batch 4 (has 1102 graphs). Loss so far: 0.0222Running epoch 6 (validation), batch 5 (has 1108 graphs). Loss so far: 0.0226Running epoch 6 (validation), batch 6 (has 1119 graphs). Loss so far: 0.0230Running epoch 6 (validation), batch 7 (has 1109 graphs). Loss so far: 0.0227Running epoch 6 (validation), batch 8 (has 1114 graphs). Loss so far: 0.0229Running epoch 6 (validation), batch 9 (has 36 graphs). Loss so far: 0.0229[K Valid: loss: 0.02285 || MAEs: 7:0.14437 | Error Ratios: 7:34.65962 || graphs/sec: 15645.76 | nodes/sec: 282500 | edges/sec: 866816
  (Best epoch so far, target metric decreased to 0.02285 from 0.04103. Saving to 'trained_models/QM9_RGAT_2025-12-15-06-38-41_77510_best_model.pickle')
== Epoch 7
Running epoch 7 (training), batch 0 (has 1116 graphs). Loss so far: 0.0318Running epoch 7 (training), batch 1 (has 1102 graphs). Loss so far: 0.0286Running epoch 7 (training), batch 2 (has 1101 graphs). Loss so far: 0.0286Running epoch 7 (training), batch 3 (has 1115 graphs). Loss so far: 0.0285Running epoch 7 (training), batch 4 (has 1120 graphs). Loss so far: 0.0285Running epoch 7 (training), batch 5 (has 1110 graphs). Loss so far: 0.0285Running epoch 7 (training), batch 6 (has 1108 graphs). Loss so far: 0.0292Running epoch 7 (training), batch 7 (has 1105 graphs). Loss so far: 0.0288Running epoch 7 (training), batch 8 (has 1114 graphs). Loss so far: 0.0282Running epoch 7 (training), batch 9 (has 1110 graphs). Loss so far: 0.0282Running epoch 7 (training), batch 10 (has 1120 graphs). Loss so far: 0.0283Running epoch 7 (training), batch 11 (has 1109 graphs). Loss so far: 0.0280Running epoch 7 (training), batch 12 (has 1105 graphs). Loss so far: 0.0276Running epoch 7 (training), batch 13 (has 1110 graphs). Loss so far: 0.0271Running epoch 7 (training), batch 14 (has 1107 graphs). Loss so far: 0.0269Running epoch 7 (training), batch 15 (has 1100 graphs). Loss so far: 0.0271Running epoch 7 (training), batch 16 (has 1120 graphs). Loss so far: 0.0273Running epoch 7 (training), batch 17 (has 1101 graphs). Loss so far: 0.0273Running epoch 7 (training), batch 18 (has 1103 graphs). Loss so far: 0.0272Running epoch 7 (training), batch 19 (has 1112 graphs). Loss so far: 0.0271Running epoch 7 (training), batch 20 (has 1119 graphs). Loss so far: 0.0271Running epoch 7 (training), batch 21 (has 1116 graphs). Loss so far: 0.0269Running epoch 7 (training), batch 22 (has 1113 graphs). Loss so far: 0.0266Running epoch 7 (training), batch 23 (has 1106 graphs). Loss so far: 0.0263Running epoch 7 (training), batch 24 (has 1105 graphs). Loss so far: 0.0262Running epoch 7 (training), batch 25 (has 1100 graphs). Loss so far: 0.0260Running epoch 7 (training), batch 26 (has 1100 graphs). Loss so far: 0.0257Running epoch 7 (training), batch 27 (has 1115 graphs). Loss so far: 0.0256Running epoch 7 (training), batch 28 (has 1116 graphs). Loss so far: 0.0254Running epoch 7 (training), batch 29 (has 1104 graphs). Loss so far: 0.0253Running epoch 7 (training), batch 30 (has 1099 graphs). Loss so far: 0.0255Running epoch 7 (training), batch 31 (has 1104 graphs). Loss so far: 0.0263Running epoch 7 (training), batch 32 (has 1108 graphs). Loss so far: 0.0287Running epoch 7 (training), batch 33 (has 1111 graphs). Loss so far: 0.0339Running epoch 7 (training), batch 34 (has 1117 graphs). Loss so far: 0.0347Running epoch 7 (training), batch 35 (has 1117 graphs). Loss so far: 0.0343Running epoch 7 (training), batch 36 (has 1116 graphs). Loss so far: 0.0346Running epoch 7 (training), batch 37 (has 1109 graphs). Loss so far: 0.0354Running epoch 7 (training), batch 38 (has 1115 graphs). Loss so far: 0.0360Running epoch 7 (training), batch 39 (has 1108 graphs). Loss so far: 0.0356Running epoch 7 (training), batch 40 (has 1103 graphs). Loss so far: 0.0357Running epoch 7 (training), batch 41 (has 1099 graphs). Loss so far: 0.0362Running epoch 7 (training), batch 42 (has 1114 graphs). Loss so far: 0.0361Running epoch 7 (training), batch 43 (has 1106 graphs). Loss so far: 0.0358Running epoch 7 (training), batch 44 (has 1105 graphs). Loss so far: 0.0358Running epoch 7 (training), batch 45 (has 1108 graphs). Loss so far: 0.0358Running epoch 7 (training), batch 46 (has 1111 graphs). Loss so far: 0.0355Running epoch 7 (training), batch 47 (has 1117 graphs). Loss so far: 0.0352Running epoch 7 (training), batch 48 (has 1108 graphs). Loss so far: 0.0352Running epoch 7 (training), batch 49 (has 1100 graphs). Loss so far: 0.0352